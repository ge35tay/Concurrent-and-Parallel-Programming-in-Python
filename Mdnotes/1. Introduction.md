## 1. Introduction

Program is usually running sequentially on one CPU, the other is sitting idle.

 We can separate different threads to do different tasks to decrease waiting time and speed up.





Python Considerations:

- Global Interpreter Lock:

  - Only one thread can be running at one time, it is not concurrent, but take turns, whenever one is idle, another one can jump in and take the CPU time

    > https://www.zhihu.com/question/25532384
    >
    > https://zhuanlan.zhihu.com/p/20953544

- Thread safe

  - Locking
  - An entity can handle multiple threads using it or threads deal with data in a way that doesn't interfere with other threads

- Race condition

  - Need avoid weird case when two thread want to access the shared data
  - Thread 1 accesses and writes to/modifies variable a
  - Thread 2 accesses and writes to/modifies variable b
  - Unpredictable result would happen
  - If we have shared data, need to consider race condition



1. Threads:
   1. Share the same memory
   2. Small overhead associated with thread switching and management
2. Multiprocessing
   1. Processes don't share memory. each process has its own python interpreter and GIL
   2. Hight overhead, memory duplication
3. Concurrency in general:
   1. More complex and hard to debug



### 1.1 Threading

The thread does not improve the time a lot, because basically it is still run sequently, but the sleeping happens in a thread level, a different thread can execute while each of these threads is sitting idle



- use a separate list to save the thread and use the .join outside the loop to block the whole execution until this thread is done (if u put inside the loop it blocks every loop execution, and the performance is not improved) 

- daemon flag: this statement means this thread, if the main program finishes, the daemon thread would no  finish



### 1.2. wiki



yield:

> https://blog.csdn.net/mieleizhi0522/article/details/82142856

static_method:

> https://www.runoob.com/python/python-func-staticmethod.html



Under an environemnt

> pip freeze > requirements.txt



### 1.3 Queue

Queue: take elements and put them in a queue

> https://blog.csdn.net/brucewong0516/article/details/85796073



### 1.4. Database Insertion Worker



## 2. Process

Process use more than 1 core so speed up the program

The amount of speed improvement we can get depends a lot on the number of  cars available



We can create a lot of processes, but the more processes we can execute simultaneously because we can execute each of them on a different cores.



Every time we start a process, we take the python interpreter and start a semi-fresh version on another process, so they are not conflicting and there are not global interpreter lock goes on 



### 2.1 Multiprocess queues

pool 的用法：

> https://www.cnblogs.com/ailiailan/p/11850710.html



当用 multiprocess中的pool map时，如果mapping的方程有多个输入，需要用到partial from functools

or just use starmap





## 3. Asynchronous

one thread running and one process.



Asynchronous 



The whole process of asynchronous execution in python is like a **event loop**, we can add task or schedule tasks with event loop. 

In the event loop we have sth like features, it represents sth that has not yet come back but sth. is going to come





after write the asynio function, we need one and just one run function, and in this run function we write on one core and one single thread





**The only difference from regular function is await and async**, with async we have to wait the respoonse from last event(function)



asyncio.task:

> https://docs.python.org/zh-cn/3/library/asyncio-task.html

asyncio.gather

> https://www.jianshu.com/p/b1c5981f82c5



### 3.1  combine multiprocessing and asyn